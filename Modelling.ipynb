{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Recommender System\n",
    "\n",
    "In this notebook we prototype a set of models to be used in order to build a Recommender System for the Amazon music data.\n",
    "\n",
    "We first establish a few simple baselines and then progress to implementing two different classes of models:\n",
    "*  Collaborative filtering models based only on user and item data (no text)\n",
    "*  A textual based model\n",
    "\n",
    "We then finally combine the best model from each class into a meta model and evaluate it's performance.\n",
    "\n",
    "We start with some necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from json into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "with open(os.path.join('data', 'train.json'), 'r') as train_file:\n",
    "    data = [json.loads(row) for row in train_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>08 24, 2010</td>\n",
       "      <td>u04428712</td>\n",
       "      <td>So is Katy Perry's new album \"Teenage Dream\" c...</td>\n",
       "      <td>Amazing that I Actually Bought This...More Ama...</td>\n",
       "      <td>1282608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$35.93</td>\n",
       "      <td>p70761125</td>\n",
       "      <td>85559980</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10 31, 2009</td>\n",
       "      <td>u06946603</td>\n",
       "      <td>I got this CD almost 10 years ago, and given t...</td>\n",
       "      <td>Excellent album</td>\n",
       "      <td>1256947200</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>$11.28</td>\n",
       "      <td>p85427891</td>\n",
       "      <td>41699565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 13, 2015</td>\n",
       "      <td>u92735614</td>\n",
       "      <td>I REALLY enjoy this pairing of Anderson and Po...</td>\n",
       "      <td>Love the Music, Hate the Light Show</td>\n",
       "      <td>1444694400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$89.86</td>\n",
       "      <td>p82172532</td>\n",
       "      <td>24751194</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>06 28, 2017</td>\n",
       "      <td>u35112935</td>\n",
       "      <td>Finally got it . It was everything thought it ...</td>\n",
       "      <td>Great</td>\n",
       "      <td>1498608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.89</td>\n",
       "      <td>p15255251</td>\n",
       "      <td>22820631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 12, 2015</td>\n",
       "      <td>u07141505</td>\n",
       "      <td>Look at all star cast.  Outstanding record, pl...</td>\n",
       "      <td>Love these guys.</td>\n",
       "      <td>1444608000</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$15.24</td>\n",
       "      <td>p82618188</td>\n",
       "      <td>53377470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>5.0</td>\n",
       "      <td>03 12, 2018</td>\n",
       "      <td>u60319848</td>\n",
       "      <td>LOve you Jerry</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1520812800</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>p57635618</td>\n",
       "      <td>78272876</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>4.0</td>\n",
       "      <td>04 14, 2011</td>\n",
       "      <td>u87292135</td>\n",
       "      <td>This album is appropriately titled \"Wasting Li...</td>\n",
       "      <td>Wasting Light Wastes None of the Band's Talent</td>\n",
       "      <td>1302739200</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.04</td>\n",
       "      <td>p39196472</td>\n",
       "      <td>64829313</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3.0</td>\n",
       "      <td>07 22, 2014</td>\n",
       "      <td>u77481859</td>\n",
       "      <td>MOTT it's NOTT! I have been a Mott and Ian Hun...</td>\n",
       "      <td>MOTT IT'S NOTT!</td>\n",
       "      <td>1405987200</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$12.98</td>\n",
       "      <td>p51004404</td>\n",
       "      <td>81054257</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>5.0</td>\n",
       "      <td>07 23, 2015</td>\n",
       "      <td>u98141334</td>\n",
       "      <td>Excelent cd, great band, great sound great exp...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1437609600</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$22.98</td>\n",
       "      <td>p10929209</td>\n",
       "      <td>53091955</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>09 23, 2003</td>\n",
       "      <td>u57618599</td>\n",
       "      <td>What a marvelous Carpenters compilation! This ...</td>\n",
       "      <td>The good old days!</td>\n",
       "      <td>1064275200</td>\n",
       "      <td>Pop</td>\n",
       "      <td>.a-section.a-spacing-mini{margin-bottom:6px!im...</td>\n",
       "      <td>p49032746</td>\n",
       "      <td>43464848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall   reviewTime reviewerID  \\\n",
       "0          4.0  08 24, 2010  u04428712   \n",
       "1          5.0  10 31, 2009  u06946603   \n",
       "2          4.0  10 13, 2015  u92735614   \n",
       "3          5.0  06 28, 2017  u35112935   \n",
       "4          4.0  10 12, 2015  u07141505   \n",
       "...        ...          ...        ...   \n",
       "19995      5.0  03 12, 2018  u60319848   \n",
       "19996      4.0  04 14, 2011  u87292135   \n",
       "19997      3.0  07 22, 2014  u77481859   \n",
       "19998      5.0  07 23, 2015  u98141334   \n",
       "19999      5.0  09 23, 2003  u57618599   \n",
       "\n",
       "                                              reviewText  \\\n",
       "0      So is Katy Perry's new album \"Teenage Dream\" c...   \n",
       "1      I got this CD almost 10 years ago, and given t...   \n",
       "2      I REALLY enjoy this pairing of Anderson and Po...   \n",
       "3      Finally got it . It was everything thought it ...   \n",
       "4      Look at all star cast.  Outstanding record, pl...   \n",
       "...                                                  ...   \n",
       "19995                                     LOve you Jerry   \n",
       "19996  This album is appropriately titled \"Wasting Li...   \n",
       "19997  MOTT it's NOTT! I have been a Mott and Ian Hun...   \n",
       "19998  Excelent cd, great band, great sound great exp...   \n",
       "19999  What a marvelous Carpenters compilation! This ...   \n",
       "\n",
       "                                                 summary  unixReviewTime  \\\n",
       "0      Amazing that I Actually Bought This...More Ama...      1282608000   \n",
       "1                                        Excellent album      1256947200   \n",
       "2                    Love the Music, Hate the Light Show      1444694400   \n",
       "3                                                  Great      1498608000   \n",
       "4                                       Love these guys.      1444608000   \n",
       "...                                                  ...             ...   \n",
       "19995                                         Five Stars      1520812800   \n",
       "19996     Wasting Light Wastes None of the Band's Talent      1302739200   \n",
       "19997                                    MOTT IT'S NOTT!      1405987200   \n",
       "19998                                         Five Stars      1437609600   \n",
       "19999                                 The good old days!      1064275200   \n",
       "\n",
       "               category                                              price  \\\n",
       "0                   Pop                                             $35.93   \n",
       "1      Alternative Rock                                             $11.28   \n",
       "2                   Pop                                             $89.86   \n",
       "3                   Pop                                             $11.89   \n",
       "4                  Jazz                                             $15.24   \n",
       "...                 ...                                                ...   \n",
       "19995               Pop                                             $19.99   \n",
       "19996               Pop                                             $11.04   \n",
       "19997               Pop                                             $12.98   \n",
       "19998              Jazz                                             $22.98   \n",
       "19999               Pop  .a-section.a-spacing-mini{margin-bottom:6px!im...   \n",
       "\n",
       "          itemID reviewHash image  \n",
       "0      p70761125   85559980   NaN  \n",
       "1      p85427891   41699565   NaN  \n",
       "2      p82172532   24751194   NaN  \n",
       "3      p15255251   22820631   NaN  \n",
       "4      p82618188   53377470   NaN  \n",
       "...          ...        ...   ...  \n",
       "19995  p57635618   78272876   NaN  \n",
       "19996  p39196472   64829313   NaN  \n",
       "19997  p51004404   81054257   NaN  \n",
       "19998  p10929209   53091955   NaN  \n",
       "19999  p49032746   43464848   NaN  \n",
       "\n",
       "[20000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df = data_df[0:20000]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to handle price so that it can be converted to a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_price(price):\n",
    "    \"\"\"Trims `price` to remove the $ sign.\n",
    "    \n",
    "    If the price variable does not have the format $x.xx\n",
    "    then the empty string is returned.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    price: str\n",
    "        A string representing a price.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string representing `price` but with the $ sign removed,\n",
    "        or the empty string if `price` does not have the correct\n",
    "        format.\n",
    "    \n",
    "    \"\"\"\n",
    "    if (not pd.isnull(price) and isinstance(price, str) and\n",
    "        len(price) > 0 and price[0] == '$'):\n",
    "        return price[1:]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We add some additional features:\n",
    "*  reviewMonth - the month in which the review was done.\n",
    "*  reviewYear - the year in which the review was done.\n",
    "*  reviewHour - the hour in which the review was done\n",
    "*  cleanedPrice - a numeric version of the price column. We only keep this column if the price is correctly formatted.\n",
    "*  fullReviewText - a column that combines the summary followed by reviewText\n",
    "*  reviewWordCount - indicates whether the record has an associated review based on the fullReviewText column\n",
    "\n",
    "We also add an indicator variable for each music category to indicate if the record is in that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-d3ba8e2e1b50>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['cleanedPrice'] = data_df['cleanedPrice'].astype('float')\n",
      "<ipython-input-5-d3ba8e2e1b50>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['fixedReviewText'] = np.where(pd.isnull(data_df['reviewText']), \"\", data_df['reviewText'])\n",
      "<ipython-input-5-d3ba8e2e1b50>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['fixedSummary'] = np.where(pd.isnull(data_df['summary']), \"\", data_df['summary'])\n",
      "<ipython-input-5-d3ba8e2e1b50>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['fullReviewText'] = data_df['fixedSummary'] + \" \" + data_df['fixedReviewText']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewHour</th>\n",
       "      <th>reviewMonthYear</th>\n",
       "      <th>cleanedPrice</th>\n",
       "      <th>fullReviewText</th>\n",
       "      <th>isPop</th>\n",
       "      <th>isAlternativeRock</th>\n",
       "      <th>isJazz</th>\n",
       "      <th>isClassical</th>\n",
       "      <th>isDanceElectronic</th>\n",
       "      <th>reviewWordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>08 24, 2010</td>\n",
       "      <td>u04428712</td>\n",
       "      <td>So is Katy Perry's new album \"Teenage Dream\" c...</td>\n",
       "      <td>Amazing that I Actually Bought This...More Ama...</td>\n",
       "      <td>1282608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$35.93</td>\n",
       "      <td>p70761125</td>\n",
       "      <td>85559980</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2010-08</td>\n",
       "      <td>35.93</td>\n",
       "      <td>Amazing that I Actually Bought This...More Ama...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10 31, 2009</td>\n",
       "      <td>u06946603</td>\n",
       "      <td>I got this CD almost 10 years ago, and given t...</td>\n",
       "      <td>Excellent album</td>\n",
       "      <td>1256947200</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>$11.28</td>\n",
       "      <td>p85427891</td>\n",
       "      <td>41699565</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2009-10</td>\n",
       "      <td>11.28</td>\n",
       "      <td>Excellent album I got this CD almost 10 years ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 13, 2015</td>\n",
       "      <td>u92735614</td>\n",
       "      <td>I REALLY enjoy this pairing of Anderson and Po...</td>\n",
       "      <td>Love the Music, Hate the Light Show</td>\n",
       "      <td>1444694400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$89.86</td>\n",
       "      <td>p82172532</td>\n",
       "      <td>24751194</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>89.86</td>\n",
       "      <td>Love the Music, Hate the Light Show I REALLY e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>06 28, 2017</td>\n",
       "      <td>u35112935</td>\n",
       "      <td>Finally got it . It was everything thought it ...</td>\n",
       "      <td>Great</td>\n",
       "      <td>1498608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.89</td>\n",
       "      <td>p15255251</td>\n",
       "      <td>22820631</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>11.89</td>\n",
       "      <td>Great Finally got it . It was everything thoug...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 12, 2015</td>\n",
       "      <td>u07141505</td>\n",
       "      <td>Look at all star cast.  Outstanding record, pl...</td>\n",
       "      <td>Love these guys.</td>\n",
       "      <td>1444608000</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$15.24</td>\n",
       "      <td>p82618188</td>\n",
       "      <td>53377470</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>15.24</td>\n",
       "      <td>Love these guys. Look at all star cast.  Outst...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>5.0</td>\n",
       "      <td>04 20, 2002</td>\n",
       "      <td>u73076812</td>\n",
       "      <td>I must have at least four different box sets o...</td>\n",
       "      <td>One of the best Trio collections out there</td>\n",
       "      <td>1019260800</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$28.43</td>\n",
       "      <td>p26751948</td>\n",
       "      <td>33022251</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2002-04</td>\n",
       "      <td>28.43</td>\n",
       "      <td>One of the best Trio collections out there I m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>5.0</td>\n",
       "      <td>03 12, 2018</td>\n",
       "      <td>u60319848</td>\n",
       "      <td>LOve you Jerry</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1520812800</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>p57635618</td>\n",
       "      <td>78272876</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-03</td>\n",
       "      <td>19.99</td>\n",
       "      <td>Five Stars LOve you Jerry</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>4.0</td>\n",
       "      <td>04 14, 2011</td>\n",
       "      <td>u87292135</td>\n",
       "      <td>This album is appropriately titled \"Wasting Li...</td>\n",
       "      <td>Wasting Light Wastes None of the Band's Talent</td>\n",
       "      <td>1302739200</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.04</td>\n",
       "      <td>p39196472</td>\n",
       "      <td>64829313</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2011-04</td>\n",
       "      <td>11.04</td>\n",
       "      <td>Wasting Light Wastes None of the Band's Talent...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3.0</td>\n",
       "      <td>07 22, 2014</td>\n",
       "      <td>u77481859</td>\n",
       "      <td>MOTT it's NOTT! I have been a Mott and Ian Hun...</td>\n",
       "      <td>MOTT IT'S NOTT!</td>\n",
       "      <td>1405987200</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$12.98</td>\n",
       "      <td>p51004404</td>\n",
       "      <td>81054257</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2014-07</td>\n",
       "      <td>12.98</td>\n",
       "      <td>MOTT IT'S NOTT! MOTT it's NOTT! I have been a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>5.0</td>\n",
       "      <td>07 23, 2015</td>\n",
       "      <td>u98141334</td>\n",
       "      <td>Excelent cd, great band, great sound great exp...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1437609600</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$22.98</td>\n",
       "      <td>p10929209</td>\n",
       "      <td>53091955</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>22.98</td>\n",
       "      <td>Five Stars Excelent cd, great band, great soun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19735 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall   reviewTime reviewerID  \\\n",
       "0          4.0  08 24, 2010  u04428712   \n",
       "1          5.0  10 31, 2009  u06946603   \n",
       "2          4.0  10 13, 2015  u92735614   \n",
       "3          5.0  06 28, 2017  u35112935   \n",
       "4          4.0  10 12, 2015  u07141505   \n",
       "...        ...          ...        ...   \n",
       "19994      5.0  04 20, 2002  u73076812   \n",
       "19995      5.0  03 12, 2018  u60319848   \n",
       "19996      4.0  04 14, 2011  u87292135   \n",
       "19997      3.0  07 22, 2014  u77481859   \n",
       "19998      5.0  07 23, 2015  u98141334   \n",
       "\n",
       "                                              reviewText  \\\n",
       "0      So is Katy Perry's new album \"Teenage Dream\" c...   \n",
       "1      I got this CD almost 10 years ago, and given t...   \n",
       "2      I REALLY enjoy this pairing of Anderson and Po...   \n",
       "3      Finally got it . It was everything thought it ...   \n",
       "4      Look at all star cast.  Outstanding record, pl...   \n",
       "...                                                  ...   \n",
       "19994  I must have at least four different box sets o...   \n",
       "19995                                     LOve you Jerry   \n",
       "19996  This album is appropriately titled \"Wasting Li...   \n",
       "19997  MOTT it's NOTT! I have been a Mott and Ian Hun...   \n",
       "19998  Excelent cd, great band, great sound great exp...   \n",
       "\n",
       "                                                 summary  unixReviewTime  \\\n",
       "0      Amazing that I Actually Bought This...More Ama...      1282608000   \n",
       "1                                        Excellent album      1256947200   \n",
       "2                    Love the Music, Hate the Light Show      1444694400   \n",
       "3                                                  Great      1498608000   \n",
       "4                                       Love these guys.      1444608000   \n",
       "...                                                  ...             ...   \n",
       "19994         One of the best Trio collections out there      1019260800   \n",
       "19995                                         Five Stars      1520812800   \n",
       "19996     Wasting Light Wastes None of the Band's Talent      1302739200   \n",
       "19997                                    MOTT IT'S NOTT!      1405987200   \n",
       "19998                                         Five Stars      1437609600   \n",
       "\n",
       "               category   price     itemID reviewHash  ... reviewHour  \\\n",
       "0                   Pop  $35.93  p70761125   85559980  ...         20   \n",
       "1      Alternative Rock  $11.28  p85427891   41699565  ...         20   \n",
       "2                   Pop  $89.86  p82172532   24751194  ...         20   \n",
       "3                   Pop  $11.89  p15255251   22820631  ...         20   \n",
       "4                  Jazz  $15.24  p82618188   53377470  ...         20   \n",
       "...                 ...     ...        ...        ...  ...        ...   \n",
       "19994               Pop  $28.43  p26751948   33022251  ...         20   \n",
       "19995               Pop  $19.99  p57635618   78272876  ...         20   \n",
       "19996               Pop  $11.04  p39196472   64829313  ...         20   \n",
       "19997               Pop  $12.98  p51004404   81054257  ...         20   \n",
       "19998              Jazz  $22.98  p10929209   53091955  ...         20   \n",
       "\n",
       "      reviewMonthYear cleanedPrice  \\\n",
       "0             2010-08        35.93   \n",
       "1             2009-10        11.28   \n",
       "2             2015-10        89.86   \n",
       "3             2017-06        11.89   \n",
       "4             2015-10        15.24   \n",
       "...               ...          ...   \n",
       "19994         2002-04        28.43   \n",
       "19995         2018-03        19.99   \n",
       "19996         2011-04        11.04   \n",
       "19997         2014-07        12.98   \n",
       "19998         2015-07        22.98   \n",
       "\n",
       "                                          fullReviewText isPop  \\\n",
       "0      Amazing that I Actually Bought This...More Ama...     1   \n",
       "1      Excellent album I got this CD almost 10 years ...     0   \n",
       "2      Love the Music, Hate the Light Show I REALLY e...     1   \n",
       "3      Great Finally got it . It was everything thoug...     1   \n",
       "4      Love these guys. Look at all star cast.  Outst...     0   \n",
       "...                                                  ...   ...   \n",
       "19994  One of the best Trio collections out there I m...     1   \n",
       "19995                          Five Stars LOve you Jerry     1   \n",
       "19996  Wasting Light Wastes None of the Band's Talent...     1   \n",
       "19997  MOTT IT'S NOTT! MOTT it's NOTT! I have been a ...     1   \n",
       "19998  Five Stars Excelent cd, great band, great soun...     0   \n",
       "\n",
       "       isAlternativeRock isJazz  isClassical  isDanceElectronic  \\\n",
       "0                      0      0            0                  0   \n",
       "1                      1      0            0                  0   \n",
       "2                      0      0            0                  0   \n",
       "3                      0      0            0                  0   \n",
       "4                      0      1            0                  0   \n",
       "...                  ...    ...          ...                ...   \n",
       "19994                  0      0            0                  0   \n",
       "19995                  0      0            0                  0   \n",
       "19996                  0      0            0                  0   \n",
       "19997                  0      0            0                  0   \n",
       "19998                  0      1            0                  0   \n",
       "\n",
       "       reviewWordCount  \n",
       "0                  277  \n",
       "1                  125  \n",
       "2                  133  \n",
       "3                   15  \n",
       "4                   21  \n",
       "...                ...  \n",
       "19994              226  \n",
       "19995                5  \n",
       "19996              165  \n",
       "19997              282  \n",
       "19998               10  \n",
       "\n",
       "[19735 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data_df['reviewMonth'] = data_df['reviewTime'].apply(lambda x: x.split(' ')[0])\n",
    "data_df['reviewYear'] = data_df['reviewTime'].apply(lambda x: x.split(' ')[2])\n",
    "data_df['reviewHour'] = data_df['unixReviewTime'].apply(lambda x: datetime.fromtimestamp(x).hour)\n",
    "data_df['reviewMonthYear'] = data_df['reviewYear'] + '-' + data_df['reviewMonth']\n",
    "\n",
    "data_df['cleanedPrice'] = data_df['price'].apply(lambda x: trim_price(x))\n",
    "data_df = data_df[data_df['cleanedPrice'] != \"\"]\n",
    "data_df['cleanedPrice'] = data_df['cleanedPrice'].astype('float')\n",
    "\n",
    "data_df['fixedReviewText'] = np.where(pd.isnull(data_df['reviewText']), \"\", data_df['reviewText'])\n",
    "data_df['fixedSummary'] = np.where(pd.isnull(data_df['summary']), \"\", data_df['summary'])\n",
    "data_df['fullReviewText'] = data_df['fixedSummary'] + \" \" + data_df['fixedReviewText']\n",
    "\n",
    "data_df = data_df.drop(columns=['fixedReviewText', 'fixedSummary'])\n",
    "\n",
    "genres = data_df['category'].unique()\n",
    "\n",
    "for genre in genres:\n",
    "    genre_col = \"is\" + genre.replace(\" \", \"\").replace(\"&\", \"\")\n",
    "    data_df[genre_col] = data_df['category'].apply(lambda x: 1 if x == genre else 0)\n",
    "\n",
    "data_df['reviewWordCount'] = data_df['fullReviewText'].apply(lambda x: len(x.split()))\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "Definining a MSE function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE(actuals, predicteds):\n",
    "    \"\"\"Calculates the Mean Squared Error between `actuals` and `predicteds`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actuals: np.array\n",
    "        A numpy array of the actual values.\n",
    "    predicteds: np.array\n",
    "        A numpy array of the predicted values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        A float representing the Mean Squared Error between `actuals` and\n",
    "        `predicteds`.\n",
    "    \n",
    "    \"\"\"\n",
    "    return (((actuals - predicteds)**2).sum()) / (len(actuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate targets and data.\n",
    "\n",
    "Then split into training and validation sets.\n",
    "\n",
    "Note that we split into validation sets for each music genre and then concatenate the data frames so that the proportion of each genre in the train and validation sets is equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "genres = data_df['category'].unique()\n",
    "X_train_set = []\n",
    "X_val_set = []\n",
    "y_train_set = []\n",
    "y_val_set = []\n",
    "\n",
    "for genre in genres:\n",
    "    genre_df = data_df[data_df['category'] == genre]\n",
    "    targets = genre_df['overall']\n",
    "    feature_data = genre_df.drop(columns=['overall'])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        feature_data, targets, shuffle=True, test_size=0.2, random_state=17)\n",
    "    X_train_set.append(X_train)\n",
    "    X_val_set.append(X_val)\n",
    "    y_train_set.append(y_train)\n",
    "    y_val_set.append(y_val)\n",
    "\n",
    "X_train = pd.concat(X_train_set)\n",
    "X_val = pd.concat(X_val_set)\n",
    "y_train = pd.concat(y_train_set)\n",
    "y_val = pd.concat(y_val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting\n",
    "\n",
    "Throughout the model fitting process we will keep 3 arrays that store the model name, training error, and validation error respectively for all models that we prototype.\n",
    "\n",
    "##### Baselines\n",
    "\n",
    "We will look at two simple baseline models.\n",
    "\n",
    "The first is the same baseline model implemented in `baseline.py`. But we will evaluate its performance on the validation set in order to fit models and compare performance on data that is distinct from the test set.\n",
    "\n",
    "In this model we simply compute the average rating and assign this as our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "train_errors = []\n",
    "validation_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_on_average(targets, avg):\n",
    "    \"\"\"Computers the error based on using average rating as the prediction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    targets: np.array\n",
    "        The actual ratings.\n",
    "    avg: float\n",
    "        The predicted rating based on an average.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        A float representing the mean squared error from predicting\n",
    "        based on `avg`.\n",
    "    \n",
    "    \"\"\"\n",
    "    return calculate_MSE(targets, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error based on average prediction: 0.984\n",
      "Validation error based on average prediction: 0.977\n"
     ]
    }
   ],
   "source": [
    "train_avg = y_train.mean()\n",
    "\n",
    "model_names.append(\"Average\")\n",
    "train_errors.append(error_on_average(y_train, train_avg))\n",
    "validation_errors.append(error_on_average(y_val, train_avg))\n",
    "\n",
    "print(\"Training error based on average prediction: %.3f\" % train_errors[0])\n",
    "print(\"Validation error based on average prediction: %.3f\" % validation_errors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second baseline model is slightly more complicated. We will calculate three types of quantities:\n",
    "*  The overall average\n",
    "*  The difference between the average rating for each item and the overall average\n",
    "*  The difference between the average rating for each user and the overall average\n",
    "\n",
    "Our prediction for a particular user and item will then be the sum of these 3 quantities.\n",
    "\n",
    "We will denote this model as Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "train_avg_total = y_train.mean()\n",
    "train_user_avg = train_df.groupby(train_df['reviewerID'], as_index=False)['overall'].mean()\n",
    "train_item_avg = train_df.groupby(train_df['itemID'], as_index=False)['overall'].mean()\n",
    "train_user_avg.columns = ['reviewerID', 'userAverage']\n",
    "train_item_avg.columns = ['itemID', 'itemAverage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_rating(rating):\n",
    "    \"\"\"Thresholds `rating` to lie in the range [1, 5].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rating: float\n",
    "        The rating to be thresholded.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        A float representing the thresholded rating.\n",
    "    \n",
    "    \"\"\"\n",
    "    if rating < 1:\n",
    "        return 1\n",
    "    if rating > 5:\n",
    "        return 5\n",
    "    return rating\n",
    "\n",
    "def weighted_average_error(X, y, total_avg, user_avgs, item_avgs):\n",
    "    \"\"\"Calculates the error based on the weighted average prediction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pd.DataFrame\n",
    "        The DataFrame of features.\n",
    "    y: np.array\n",
    "        A numpy array containing the targets\n",
    "    total_avg: float\n",
    "        The average across all users/items.\n",
    "    user_avgs: pd.DataFrame\n",
    "        A DataFrame containing the average rating for each user.\n",
    "    item_avgs: pd.DataFrame\n",
    "        A DataFrame containing the average rating for each item.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        A float representing the mean squared error of the predictions.\n",
    "    \n",
    "    \"\"\"\n",
    "    df_user = pd.merge(X, user_avgs, how='left', on=['reviewerID'])\n",
    "    df_final = pd.merge(df_user, item_avgs, how='left', on=['itemID'])\n",
    "    df_final = df_final[['userAverage', 'itemAverage']]\n",
    "    df_final.fillna(total_avg)\n",
    "    df_final['pred'] = df_final['userAverage'] + df_final['itemAverage'] - total_avg\n",
    "    df_final['pred'].apply(lambda x: threshold_rating(x))\n",
    "    return calculate_MSE(y, df_final['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error based on weighted average prediction: 2.618\n",
      "Validation error based on weighted average prediction: 0.093\n"
     ]
    }
   ],
   "source": [
    "train_MSE = weighted_average_error(X_train, y_train, train_avg_total, train_user_avg, train_item_avg)\n",
    "val_MSE = weighted_average_error(X_val, y_val, train_avg_total, train_user_avg, train_item_avg)\n",
    "\n",
    "model_names.append(\"Weighted Average\")\n",
    "train_errors.append(train_MSE)\n",
    "validation_errors.append(val_MSE)\n",
    "\n",
    "print(\"Training error based on weighted average prediction: %.3f\" % train_MSE)\n",
    "print(\"Validation error based on weighted average prediction: %.3f\" % val_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Models\n",
    "\n",
    "In this section we build a set of feature based models to predict ratings on our validation set and compare their performance. These models do not follow the typical recommender system approach of collaborative filtering / matrix factorization\n",
    "\n",
    "We start with a linear regression model. At this stage we do not have a lot of features and so it makes more sense to use the $L_{2}$-norm for regularization (a.k.a. ridge regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['cleanedPrice', 'isPop', 'isAlternativeRock', 'isJazz', 'isClassical', 'isDanceElectronic', 'reviewWordCount']\n",
    "X_train_reg = X_train[columns_to_keep]\n",
    "X_val_reg = X_val[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-e7d4db21d8ef>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_reg['reviewWordCount'] = X_train_reg['reviewWordCount'].apply(lambda x: np.log(x))\n",
      "<ipython-input-31-e7d4db21d8ef>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val_reg['reviewWordCount'] = X_val_reg['reviewWordCount'].apply(lambda x: np.log(x))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_reg['reviewWordCount'] = X_train_reg['reviewWordCount'].apply(lambda x: np.log(x))\n",
    "X_val_reg['reviewWordCount'] = X_val_reg['reviewWordCount'].apply(lambda x: np.log(x))\n",
    "\n",
    "X_train_reg = min_max_scaler.fit_transform(X_train_reg)\n",
    "X_val_reg = min_max_scaler.transform(X_val_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0.0\n",
      "------------\n",
      "Training Error: 0.9550244154429685\n",
      "Validation Error: 0.9533155393424353\n",
      "\n",
      "Alpha = 0.01\n",
      "------------\n",
      "Training Error: 0.9550248555325158\n",
      "Validation Error: 0.9533145486453865\n",
      "\n",
      "Alpha = 0.03\n",
      "------------\n",
      "Training Error: 0.9550257401702213\n",
      "Validation Error: 0.9533125835818699\n",
      "\n",
      "Alpha = 0.1\n",
      "------------\n",
      "Training Error: 0.9550288816532788\n",
      "Validation Error: 0.9533058738935752\n",
      "\n",
      "Alpha = 0.3\n",
      "------------\n",
      "Training Error: 0.9550382062304418\n",
      "Validation Error: 0.9532880625744887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "vthreshold_rating = np.vectorize(threshold_rating)\n",
    "\n",
    "alphas = [0.0, 0.01, 0.03, 0.1, 0.3]\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha = {}\".format(alpha))\n",
    "    print(\"------------\")\n",
    "    reg_model = Ridge(alpha=alpha)\n",
    "    reg_model.fit(X_train_reg, y_train)\n",
    "    print(\"Training Error: {}\".format(calculate_MSE(y_train, vthreshold_rating(reg_model.predict(X_train_reg)))))\n",
    "    print(\"Validation Error: {}\".format(calculate_MSE(y_val, vthreshold_rating(reg_model.predict(X_val_reg)))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After $\\alpha = 0.01$ the MSE does not marginally change and so we will use a regularization term of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error based on L2 regularized regression prediction: 0.955\n",
      "Validation error based on L2 regularized regression prediction: 0.953\n"
     ]
    }
   ],
   "source": [
    "reg_model = Ridge(alpha=0.01)\n",
    "reg_model.fit(X_train_reg, y_train)\n",
    "\n",
    "train_MSE = calculate_MSE(y_train, vthreshold_rating(reg_model.predict(X_train_reg)))\n",
    "val_MSE = calculate_MSE(y_val, vthreshold_rating(reg_model.predict(X_val_reg)))\n",
    "\n",
    "model_names.append(\"L2-Reg\")\n",
    "train_errors.append(train_MSE)\n",
    "validation_errors.append(val_MSE)\n",
    "\n",
    "print(\"Training error based on L2 regularized regression prediction: %.3f\" % train_MSE)\n",
    "print(\"Validation error based on L2 regularized regression prediction: %.3f\" % val_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at some natural language processing models.\n",
    "\n",
    "We start by processing the review column. This involves the following:\n",
    "* Removing all non-alphanumeric characters\n",
    "* converting to lower case\n",
    "* removing a set of exclusion words (the english stopwords)\n",
    "* and stemming (getting the root word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Matthew/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def process_review_text(review_text, exclude_text, ps):\n",
    "    \"\"\"Pre-processes the text given by `review_text`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    review_text: str\n",
    "        The review text to be processed.\n",
    "    exclude_text: collection\n",
    "        A collection of words to be excluded.\n",
    "    ps: PorterStemmer\n",
    "        The PorterStemmer used to perform word stemming.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string representing the processed version of `review_text`.\n",
    "    \n",
    "    \"\"\"\n",
    "    review = re.sub('[^a-zA-Z0-9]', ' ', review_text).lower().split()\n",
    "    review = [ps.stem(word) for word in review if not word in exclude_text]\n",
    "    return ' '.join(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewMonthYear</th>\n",
       "      <th>cleanedPrice</th>\n",
       "      <th>fullReviewText</th>\n",
       "      <th>isPop</th>\n",
       "      <th>isAlternativeRock</th>\n",
       "      <th>isJazz</th>\n",
       "      <th>isClassical</th>\n",
       "      <th>isDanceElectronic</th>\n",
       "      <th>reviewWordCount</th>\n",
       "      <th>processedReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>11 14, 2006</td>\n",
       "      <td>u59086436</td>\n",
       "      <td>Released in conjuction with the mock-documenta...</td>\n",
       "      <td>A True Pop Gem</td>\n",
       "      <td>1163462400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$5.84</td>\n",
       "      <td>p53306771</td>\n",
       "      <td>81549761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006-11</td>\n",
       "      <td>5.84</td>\n",
       "      <td>A True Pop Gem Released in conjuction with the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>471</td>\n",
       "      <td>true pop gem releas conjuct mock documentari f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>02 17, 2006</td>\n",
       "      <td>u15975953</td>\n",
       "      <td>'The Mamas &amp; The Papas, 16 of Their Greatest H...</td>\n",
       "      <td>Totally Evocative of our Youth.</td>\n",
       "      <td>1140134400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$7.06</td>\n",
       "      <td>p02023893</td>\n",
       "      <td>38511203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006-02</td>\n",
       "      <td>7.06</td>\n",
       "      <td>Totally Evocative of our Youth. 'The Mamas &amp; T...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>total evoc youth mama papa 16 greatest hit qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>08 29, 2016</td>\n",
       "      <td>u36717398</td>\n",
       "      <td>This is my favorite Lady Gaga CD.  I play it a...</td>\n",
       "      <td>Lady Gaga's Become a Favorite of Mine</td>\n",
       "      <td>1472428800</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$26.56</td>\n",
       "      <td>p42917906</td>\n",
       "      <td>50060419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>26.56</td>\n",
       "      <td>Lady Gaga's Become a Favorite of Mine This is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>ladi gaga becom favorit mine favorit ladi gaga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>11 1, 2016</td>\n",
       "      <td>u50807686</td>\n",
       "      <td>I may be too harsh in giving this album only 3...</td>\n",
       "      <td>Good but not as special as their other albums</td>\n",
       "      <td>1477958400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.21</td>\n",
       "      <td>p95754874</td>\n",
       "      <td>05446185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>11.21</td>\n",
       "      <td>Good but not as special as their other albums ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>good special album may harsh give album 3 star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19049</th>\n",
       "      <td>01 14, 2015</td>\n",
       "      <td>u67619343</td>\n",
       "      <td>Male quartets used to be so popular and this g...</td>\n",
       "      <td>Those days one could understand every word the...</td>\n",
       "      <td>1421193600</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$9.95</td>\n",
       "      <td>p16122621</td>\n",
       "      <td>56569540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-01</td>\n",
       "      <td>9.95</td>\n",
       "      <td>Those days one could understand every word the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>day one could understand everi word sang harmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11701</th>\n",
       "      <td>12 23, 2010</td>\n",
       "      <td>u32058100</td>\n",
       "      <td>At first I was really let down with this album...</td>\n",
       "      <td>Took some time...</td>\n",
       "      <td>1293062400</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$2.02</td>\n",
       "      <td>p91276678</td>\n",
       "      <td>50571640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Took some time... At first I was really let do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>took time first realli let album weird deadmau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>02 17, 2015</td>\n",
       "      <td>u72292741</td>\n",
       "      <td>like</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1424131200</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$13.96</td>\n",
       "      <td>p87964435</td>\n",
       "      <td>31658850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>13.96</td>\n",
       "      <td>Four Stars like</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>four star like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>05 3, 2000</td>\n",
       "      <td>u17343788</td>\n",
       "      <td>Moby's latest album touches on many genres of ...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>957312000</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$6.99</td>\n",
       "      <td>p33557762</td>\n",
       "      <td>03321056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-05</td>\n",
       "      <td>6.99</td>\n",
       "      <td>Excellent Moby's latest album touches on many ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>excel mobi latest album touch mani genr music ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19646</th>\n",
       "      <td>11 2, 2009</td>\n",
       "      <td>u15370865</td>\n",
       "      <td>This is by far one of JR's best albums to date...</td>\n",
       "      <td>Another great album by JR</td>\n",
       "      <td>1257120000</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$9.95</td>\n",
       "      <td>p62149488</td>\n",
       "      <td>69626205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2009-11</td>\n",
       "      <td>9.95</td>\n",
       "      <td>Another great album by JR This is by far one o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>anoth great album jr far one jr best album dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9721</th>\n",
       "      <td>08 10, 2013</td>\n",
       "      <td>u83424830</td>\n",
       "      <td>There has always been a love for Phyllis Hyman...</td>\n",
       "      <td>Somewhere in my heart</td>\n",
       "      <td>1376092800</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$25.98</td>\n",
       "      <td>p38404448</td>\n",
       "      <td>69744484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-08</td>\n",
       "      <td>25.98</td>\n",
       "      <td>Somewhere in my heart There has always been a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>somewher heart alway love phylli hyman heart c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15786 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewTime reviewerID  \\\n",
       "161    11 14, 2006  u59086436   \n",
       "7950   02 17, 2006  u15975953   \n",
       "1409   08 29, 2016  u36717398   \n",
       "18573   11 1, 2016  u50807686   \n",
       "19049  01 14, 2015  u67619343   \n",
       "...            ...        ...   \n",
       "11701  12 23, 2010  u32058100   \n",
       "6058   02 17, 2015  u72292741   \n",
       "2546    05 3, 2000  u17343788   \n",
       "19646   11 2, 2009  u15370865   \n",
       "9721   08 10, 2013  u83424830   \n",
       "\n",
       "                                              reviewText  \\\n",
       "161    Released in conjuction with the mock-documenta...   \n",
       "7950   'The Mamas & The Papas, 16 of Their Greatest H...   \n",
       "1409   This is my favorite Lady Gaga CD.  I play it a...   \n",
       "18573  I may be too harsh in giving this album only 3...   \n",
       "19049  Male quartets used to be so popular and this g...   \n",
       "...                                                  ...   \n",
       "11701  At first I was really let down with this album...   \n",
       "6058                                                like   \n",
       "2546   Moby's latest album touches on many genres of ...   \n",
       "19646  This is by far one of JR's best albums to date...   \n",
       "9721   There has always been a love for Phyllis Hyman...   \n",
       "\n",
       "                                                 summary  unixReviewTime  \\\n",
       "161                                       A True Pop Gem      1163462400   \n",
       "7950                     Totally Evocative of our Youth.      1140134400   \n",
       "1409               Lady Gaga's Become a Favorite of Mine      1472428800   \n",
       "18573      Good but not as special as their other albums      1477958400   \n",
       "19049  Those days one could understand every word the...      1421193600   \n",
       "...                                                  ...             ...   \n",
       "11701                                  Took some time...      1293062400   \n",
       "6058                                          Four Stars      1424131200   \n",
       "2546                                           Excellent       957312000   \n",
       "19646                          Another great album by JR      1257120000   \n",
       "9721                               Somewhere in my heart      1376092800   \n",
       "\n",
       "                 category   price     itemID reviewHash image  ...  \\\n",
       "161                   Pop   $5.84  p53306771   81549761   NaN  ...   \n",
       "7950                  Pop   $7.06  p02023893   38511203   NaN  ...   \n",
       "1409                  Pop  $26.56  p42917906   50060419   NaN  ...   \n",
       "18573                 Pop  $11.21  p95754874   05446185   NaN  ...   \n",
       "19049                 Pop   $9.95  p16122621   56569540   NaN  ...   \n",
       "...                   ...     ...        ...        ...   ...  ...   \n",
       "11701  Dance & Electronic   $2.02  p91276678   50571640   NaN  ...   \n",
       "6058   Dance & Electronic  $13.96  p87964435   31658850   NaN  ...   \n",
       "2546   Dance & Electronic   $6.99  p33557762   03321056   NaN  ...   \n",
       "19646  Dance & Electronic   $9.95  p62149488   69626205   NaN  ...   \n",
       "9721   Dance & Electronic  $25.98  p38404448   69744484   NaN  ...   \n",
       "\n",
       "      reviewMonthYear cleanedPrice  \\\n",
       "161           2006-11         5.84   \n",
       "7950          2006-02         7.06   \n",
       "1409          2016-08        26.56   \n",
       "18573         2016-11        11.21   \n",
       "19049         2015-01         9.95   \n",
       "...               ...          ...   \n",
       "11701         2010-12         2.02   \n",
       "6058          2015-02        13.96   \n",
       "2546          2000-05         6.99   \n",
       "19646         2009-11         9.95   \n",
       "9721          2013-08        25.98   \n",
       "\n",
       "                                          fullReviewText isPop  \\\n",
       "161    A True Pop Gem Released in conjuction with the...     1   \n",
       "7950   Totally Evocative of our Youth. 'The Mamas & T...     1   \n",
       "1409   Lady Gaga's Become a Favorite of Mine This is ...     1   \n",
       "18573  Good but not as special as their other albums ...     1   \n",
       "19049  Those days one could understand every word the...     1   \n",
       "...                                                  ...   ...   \n",
       "11701  Took some time... At first I was really let do...     0   \n",
       "6058                                     Four Stars like     0   \n",
       "2546   Excellent Moby's latest album touches on many ...     0   \n",
       "19646  Another great album by JR This is by far one o...     0   \n",
       "9721   Somewhere in my heart There has always been a ...     0   \n",
       "\n",
       "       isAlternativeRock isJazz  isClassical  isDanceElectronic  \\\n",
       "161                    0      0            0                  0   \n",
       "7950                   0      0            0                  0   \n",
       "1409                   0      0            0                  0   \n",
       "18573                  0      0            0                  0   \n",
       "19049                  0      0            0                  0   \n",
       "...                  ...    ...          ...                ...   \n",
       "11701                  0      0            0                  1   \n",
       "6058                   0      0            0                  1   \n",
       "2546                   0      0            0                  1   \n",
       "19646                  0      0            0                  1   \n",
       "9721                   0      0            0                  1   \n",
       "\n",
       "       reviewWordCount                                    processedReview  \n",
       "161                471  true pop gem releas conjuct mock documentari f...  \n",
       "7950               197  total evoc youth mama papa 16 greatest hit qui...  \n",
       "1409               195  ladi gaga becom favorit mine favorit ladi gaga...  \n",
       "18573              201  good special album may harsh give album 3 star...  \n",
       "19049               56  day one could understand everi word sang harmo...  \n",
       "...                ...                                                ...  \n",
       "11701               95  took time first realli let album weird deadmau...  \n",
       "6058                 3                                     four star like  \n",
       "2546                80  excel mobi latest album touch mani genr music ...  \n",
       "19646               30  anoth great album jr far one jr best album dat...  \n",
       "9721                39  somewher heart alway love phylli hyman heart c...  \n",
       "\n",
       "[15786 rows x 23 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_english = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "X_train['processedReview'] = X_train['fullReviewText'].apply(lambda x: process_review_text(x, exclude_english, ps))\n",
    "X_val['processedReview'] = X_val['fullReviewText'].apply(lambda x: process_review_text(x, exclude_english, ps))\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use a CountVectorizer to build counts of the 1500 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X_train_cv = cv.fit_transform(X_train['processedReview'])\n",
    "X_val_cv = cv.transform(X_val['processedReview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "X_train_reg_sp = sp.csr_matrix(X_train_reg)\n",
    "X_train_cv_reg = sp.hstack((X_train_cv, X_train_reg_sp), format='csr')\n",
    "\n",
    "X_val_reg_sp = sp.csr_matrix(X_val_reg)\n",
    "X_val_cv_reg = sp.hstack((X_val_cv, X_val_reg_sp), format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will fit a few sample models to this dataset.\n",
    "\n",
    "First we will perform linear regression. In this case we use $L_{1}$ regularization as we have 1507 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0\n",
      "------------\n",
      "Training Error: 0.9702267832256429\n",
      "Validation Error: 0.7343669218867732\n",
      "\n",
      "Alpha = 0.001\n",
      "------------\n",
      "Training Error: 1.0172938046370201\n",
      "Validation Error: 0.7084168824390358\n",
      "\n",
      "Alpha = 0.003\n",
      "------------\n",
      "Training Error: 1.0505511212466743\n",
      "Validation Error: 0.7278164470848788\n",
      "\n",
      "Alpha = 0.01\n",
      "------------\n",
      "Training Error: 0.7878701843021085\n",
      "Validation Error: 0.8028965298964436\n",
      "\n",
      "Alpha = 0.03\n",
      "------------\n",
      "Training Error: 0.9012085275848064\n",
      "Validation Error: 0.9024814384396381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "\n",
    "print(\"Alpha = 0\")\n",
    "print(\"------------\")\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train_cv_reg, y_train)\n",
    "print(\"Training Error: {}\".format(calculate_MSE(y_train, vthreshold_rating(reg_model.predict(X_train_cv_reg)))))\n",
    "print(\"Validation Error: {}\".format(calculate_MSE(y_val, vthreshold_rating(reg_model.predict(X_val_cv_reg)))))\n",
    "print()\n",
    "\n",
    "alphas = [0.001, 0.003, 0.01, 0.03]\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha = {}\".format(alpha))\n",
    "    print(\"------------\")\n",
    "    reg_model = Lasso(alpha=alpha)\n",
    "    reg_model.fit(X_train_cv_reg, y_train)\n",
    "    print(\"Training Error: {}\".format(calculate_MSE(y_train, vthreshold_rating(reg_model.predict(X_train_cv_reg)))))\n",
    "    print(\"Validation Error: {}\".format(calculate_MSE(y_val, vthreshold_rating(reg_model.predict(X_val_cv_reg)))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A value of $\\alpha = 0.01$ seems to work the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error based on L2 regularized regression prediction: 0.788\n",
      "Validation error based on L2 regularized regression prediction: 0.803\n"
     ]
    }
   ],
   "source": [
    "reg_model = Lasso(alpha=0.01)\n",
    "reg_model.fit(X_train_cv_reg, y_train)\n",
    "\n",
    "train_MSE = calculate_MSE(y_train, vthreshold_rating(reg_model.predict(X_train_cv_reg)))\n",
    "val_MSE = calculate_MSE(y_val, vthreshold_rating(reg_model.predict(X_val_cv_reg)))\n",
    "\n",
    "model_names.append(\"CV-L1-Reg\")\n",
    "train_errors.append(train_MSE)\n",
    "validation_errors.append(val_MSE)\n",
    "\n",
    "print(\"Training error based on L2 regularized regression prediction: %.3f\" % train_MSE)\n",
    "print(\"Validation error based on L2 regularized regression prediction: %.3f\" % val_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try a DecisionTreeRegressor and we will try various values for `min_samples_split`. This is the minimum number of samples required to split an internal node. Intuitively, lower values will correspond to higher variance and thus overfitting, whereas higher values will correspond to higher bias and thus overfitting. Obviously, this value show be at least 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Split = 2\n",
      "-------------------\n",
      "Training Error: 0.0\n",
      "Validation Error: 1.3621169916434541\n",
      "\n",
      "Samples Split = 5\n",
      "-------------------\n",
      "Training Error: 0.061990582372566404\n",
      "Validation Error: 1.2772255986044287\n",
      "\n",
      "Samples Split = 10\n",
      "-------------------\n",
      "Training Error: 0.14434726168857676\n",
      "Validation Error: 1.1985976957818383\n",
      "\n",
      "Samples Split = 20\n",
      "-------------------\n",
      "Training Error: 0.21662396829778507\n",
      "Validation Error: 1.139970892726337\n",
      "\n",
      "Samples Split = 50\n",
      "-------------------\n",
      "Training Error: 0.3487511087905338\n",
      "Validation Error: 1.0140588194819098\n",
      "\n",
      "Samples Split = 100\n",
      "-------------------\n",
      "Training Error: 0.4179916778859212\n",
      "Validation Error: 0.9681598567080321\n",
      "\n",
      "Samples Split = 200\n",
      "-------------------\n",
      "Training Error: 0.4994314849422262\n",
      "Validation Error: 0.9277689865884085\n",
      "\n",
      "Samples Split = 500\n",
      "-------------------\n",
      "Training Error: 0.636519419002298\n",
      "Validation Error: 0.8577306502336626\n",
      "\n",
      "Samples Split = 1000\n",
      "-------------------\n",
      "Training Error: 0.7138154668215363\n",
      "Validation Error: 0.819981661067408\n",
      "\n",
      "Samples Split = 2000\n",
      "-------------------\n",
      "Training Error: 0.7808885440528472\n",
      "Validation Error: 0.8113020475243286\n",
      "\n",
      "Samples Split = 5000\n",
      "-------------------\n",
      "Training Error: 0.8167709375810198\n",
      "Validation Error: 0.831837848458731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "samples_split_lst = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "\n",
    "for samples_split in samples_split_lst:\n",
    "    print(\"Samples Split = {}\".format(samples_split))\n",
    "    print(\"-------------------\")\n",
    "    tree_model = DecisionTreeRegressor(criterion=\"mse\", min_samples_split=samples_split)\n",
    "    tree_model.fit(X_train_cv_reg, y_train)\n",
    "    print(\"Training Error: {}\".format(calculate_MSE(y_train, vthreshold_rating(tree_model.predict(X_train_cv_reg)))))\n",
    "    print(\"Validation Error: {}\".format(calculate_MSE(y_val, vthreshold_rating(tree_model.predict(X_val_cv_reg)))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low values of `min_samples_split` clearly show overfitting as the training error is very low but with very high validation error. Conversely, once `min_samples_split` is past 1000 the validation error is not changing much and starts to increase. So we will stick with a value of 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error based on L2 regularized regression prediction: 0.714\n",
      "Validation error based on L2 regularized regression prediction: 0.814\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeRegressor(criterion=\"mse\", min_samples_split=1000)\n",
    "tree_model.fit(X_train_cv_reg, y_train)\n",
    "\n",
    "train_MSE = calculate_MSE(y_train, vthreshold_rating(tree_model.predict(X_train_cv_reg)))\n",
    "val_MSE = calculate_MSE(y_val, vthreshold_rating(tree_model.predict(X_val_cv_reg)))\n",
    "\n",
    "model_names.append(\"CV-DecTree\")\n",
    "train_errors.append(train_MSE)\n",
    "validation_errors.append(val_MSE)\n",
    "\n",
    "print(\"Training error based on L2 regularized regression prediction: %.3f\" % train_MSE)\n",
    "print(\"Validation error based on L2 regularized regression prediction: %.3f\" % val_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc2515-env-3.8",
   "language": "python",
   "name": "csc2515-env-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
