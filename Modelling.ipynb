{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Recommender System\n",
    "\n",
    "In this notebook we prototype a set of models to be used in order to build a Recommender System for the Amazon music data.\n",
    "\n",
    "We first establish a few simple baselines and then progress to implementing two different classes of models:\n",
    "*  Collaborative filtering models based only on user and item data (no text)\n",
    "*  A textual based model\n",
    "\n",
    "We then finally combine the best model from each class into a meta model and evaluate it's performance.\n",
    "\n",
    "We start with some necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from json into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "with open(os.path.join('data', 'train.json'), 'r') as train_file:\n",
    "    data = [json.loads(row) for row in train_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>08 24, 2010</td>\n",
       "      <td>u04428712</td>\n",
       "      <td>So is Katy Perry's new album \"Teenage Dream\" c...</td>\n",
       "      <td>Amazing that I Actually Bought This...More Ama...</td>\n",
       "      <td>1282608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$35.93</td>\n",
       "      <td>p70761125</td>\n",
       "      <td>85559980</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10 31, 2009</td>\n",
       "      <td>u06946603</td>\n",
       "      <td>I got this CD almost 10 years ago, and given t...</td>\n",
       "      <td>Excellent album</td>\n",
       "      <td>1256947200</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>$11.28</td>\n",
       "      <td>p85427891</td>\n",
       "      <td>41699565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 13, 2015</td>\n",
       "      <td>u92735614</td>\n",
       "      <td>I REALLY enjoy this pairing of Anderson and Po...</td>\n",
       "      <td>Love the Music, Hate the Light Show</td>\n",
       "      <td>1444694400</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$89.86</td>\n",
       "      <td>p82172532</td>\n",
       "      <td>24751194</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>06 28, 2017</td>\n",
       "      <td>u35112935</td>\n",
       "      <td>Finally got it . It was everything thought it ...</td>\n",
       "      <td>Great</td>\n",
       "      <td>1498608000</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.89</td>\n",
       "      <td>p15255251</td>\n",
       "      <td>22820631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10 12, 2015</td>\n",
       "      <td>u07141505</td>\n",
       "      <td>Look at all star cast.  Outstanding record, pl...</td>\n",
       "      <td>Love these guys.</td>\n",
       "      <td>1444608000</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>$15.24</td>\n",
       "      <td>p82618188</td>\n",
       "      <td>53377470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>4.0</td>\n",
       "      <td>05 1, 2004</td>\n",
       "      <td>u68902609</td>\n",
       "      <td>With this, Mariah's third album, Mariah proved...</td>\n",
       "      <td>Well Done Mariah! You Show 'Em!</td>\n",
       "      <td>1083369600</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$7.98</td>\n",
       "      <td>p84118731</td>\n",
       "      <td>35077372</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>5.0</td>\n",
       "      <td>02 27, 2017</td>\n",
       "      <td>u15269603</td>\n",
       "      <td>Fantastic CD.  All the hits are here and even ...</td>\n",
       "      <td>Great collection, excellent sound!</td>\n",
       "      <td>1488153600</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$11.49</td>\n",
       "      <td>p08613950</td>\n",
       "      <td>09788722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>3.0</td>\n",
       "      <td>03 1, 2011</td>\n",
       "      <td>u25124021</td>\n",
       "      <td>This recording is rather disappointing, to a c...</td>\n",
       "      <td>Odd Couplings</td>\n",
       "      <td>1298937600</td>\n",
       "      <td>Classical</td>\n",
       "      <td>$13.57</td>\n",
       "      <td>p25341819</td>\n",
       "      <td>71627957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>5.0</td>\n",
       "      <td>03 20, 2016</td>\n",
       "      <td>u04485604</td>\n",
       "      <td>Get it now ! Right now ! I am partial. I am a ...</td>\n",
       "      <td>Our Poet</td>\n",
       "      <td>1458432000</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>$11.07</td>\n",
       "      <td>p19134748</td>\n",
       "      <td>27463540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 28, 2012</td>\n",
       "      <td>u91032625</td>\n",
       "      <td>Demi Lovato cd was a big hit with my granddaug...</td>\n",
       "      <td>demi lovato</td>\n",
       "      <td>1327708800</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$7.00</td>\n",
       "      <td>p72631564</td>\n",
       "      <td>25270037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall   reviewTime reviewerID  \\\n",
       "0           4.0  08 24, 2010  u04428712   \n",
       "1           5.0  10 31, 2009  u06946603   \n",
       "2           4.0  10 13, 2015  u92735614   \n",
       "3           5.0  06 28, 2017  u35112935   \n",
       "4           4.0  10 12, 2015  u07141505   \n",
       "...         ...          ...        ...   \n",
       "199995      4.0   05 1, 2004  u68902609   \n",
       "199996      5.0  02 27, 2017  u15269603   \n",
       "199997      3.0   03 1, 2011  u25124021   \n",
       "199998      5.0  03 20, 2016  u04485604   \n",
       "199999      5.0  01 28, 2012  u91032625   \n",
       "\n",
       "                                               reviewText  \\\n",
       "0       So is Katy Perry's new album \"Teenage Dream\" c...   \n",
       "1       I got this CD almost 10 years ago, and given t...   \n",
       "2       I REALLY enjoy this pairing of Anderson and Po...   \n",
       "3       Finally got it . It was everything thought it ...   \n",
       "4       Look at all star cast.  Outstanding record, pl...   \n",
       "...                                                   ...   \n",
       "199995  With this, Mariah's third album, Mariah proved...   \n",
       "199996  Fantastic CD.  All the hits are here and even ...   \n",
       "199997  This recording is rather disappointing, to a c...   \n",
       "199998  Get it now ! Right now ! I am partial. I am a ...   \n",
       "199999  Demi Lovato cd was a big hit with my granddaug...   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "0       Amazing that I Actually Bought This...More Ama...      1282608000   \n",
       "1                                         Excellent album      1256947200   \n",
       "2                     Love the Music, Hate the Light Show      1444694400   \n",
       "3                                                   Great      1498608000   \n",
       "4                                        Love these guys.      1444608000   \n",
       "...                                                   ...             ...   \n",
       "199995                    Well Done Mariah! You Show 'Em!      1083369600   \n",
       "199996                 Great collection, excellent sound!      1488153600   \n",
       "199997                                      Odd Couplings      1298937600   \n",
       "199998                                           Our Poet      1458432000   \n",
       "199999                                        demi lovato      1327708800   \n",
       "\n",
       "                category   price     itemID reviewHash image  \n",
       "0                    Pop  $35.93  p70761125   85559980   NaN  \n",
       "1       Alternative Rock  $11.28  p85427891   41699565   NaN  \n",
       "2                    Pop  $89.86  p82172532   24751194   NaN  \n",
       "3                    Pop  $11.89  p15255251   22820631   NaN  \n",
       "4                   Jazz  $15.24  p82618188   53377470   NaN  \n",
       "...                  ...     ...        ...        ...   ...  \n",
       "199995               Pop   $7.98  p84118731   35077372   NaN  \n",
       "199996               Pop  $11.49  p08613950   09788722   NaN  \n",
       "199997         Classical  $13.57  p25341819   71627957   NaN  \n",
       "199998  Alternative Rock  $11.07  p19134748   27463540   NaN  \n",
       "199999               Pop   $7.00  p72631564   25270037   NaN  \n",
       "\n",
       "[200000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to handle price so that it can be converted to a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_price(price):\n",
    "    \"\"\"Trims `price` to remove the $ sign.\n",
    "    \n",
    "    If the price variable does not have the format $x.xx\n",
    "    then the empty string is returned.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    price: str\n",
    "        A string representing a price.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string representing `price` but with the $ sign removed,\n",
    "        or the empty string if `price` does not have the correct\n",
    "        format.\n",
    "    \n",
    "    \"\"\"\n",
    "    if (not pd.isnull(price) and isinstance(price, str) and\n",
    "        len(price) > 0 and price[0] == '$'):\n",
    "        return price[1:]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We add some additional features:\n",
    "*  reviewMonth - the month in which the review was done.\n",
    "*  reviewYear - the year in which the review was done.\n",
    "*  reviewHour - the hour in which the review was done\n",
    "*  cleanedPrice - a numeric version of the price column. We only keep this column if the price is correctly formatted.\n",
    "*  fullReviewText - a column that combines the summary followed by reviewText\n",
    "*  hasReviewText - indicates whether the record has an associated review based on the fullReviewText column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-837b79f88179>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['cleanedPrice'] = data_df['cleanedPrice'].astype('float')\n",
      "<ipython-input-5-837b79f88179>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['fixedReviewText'] = np.where(pd.isnull(data_df['reviewText']), \"\", data_df['reviewText'])\n",
      "<ipython-input-5-837b79f88179>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['fixedSummary'] = np.where(pd.isnull(data_df['summary']), \"\", data_df['summary'])\n",
      "<ipython-input-5-837b79f88179>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['fullReviewText'] = data_df['fixedSummary'] + \" \" + data_df['fixedReviewText']\n",
      "<ipython-input-5-837b79f88179>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['hasReviewText'] = data_df['fullReviewText'].apply(lambda x: 0 if x == \"\" or x == \" \" else 1)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data_df['reviewMonth'] = data_df['reviewTime'].apply(lambda x: x.split(' ')[0])\n",
    "data_df['reviewYear'] = data_df['reviewTime'].apply(lambda x: x.split(' ')[2])\n",
    "data_df['reviewHour'] = data_df['unixReviewTime'].apply(lambda x: datetime.fromtimestamp(x).hour)\n",
    "data_df['reviewMonthYear'] = data_df['reviewYear'] + '-' + data_df['reviewMonth']\n",
    "\n",
    "data_df['cleanedPrice'] = data_df['price'].apply(lambda x: trim_price(x))\n",
    "data_df = data_df[data_df['cleanedPrice'] != \"\"]\n",
    "data_df['cleanedPrice'] = data_df['cleanedPrice'].astype('float')\n",
    "\n",
    "data_df['fixedReviewText'] = np.where(pd.isnull(data_df['reviewText']), \"\", data_df['reviewText'])\n",
    "data_df['fixedSummary'] = np.where(pd.isnull(data_df['summary']), \"\", data_df['summary'])\n",
    "data_df['fullReviewText'] = data_df['fixedSummary'] + \" \" + data_df['fixedReviewText']\n",
    "\n",
    "data_df['hasReviewText'] = data_df['fullReviewText'].apply(lambda x: 0 if x == \"\" or x == \" \" else 1)\n",
    "\n",
    "data_df = data_df.drop(columns=['fixedReviewText', 'fixedSummary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "Definining a MSE function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE(actuals, predicteds):\n",
    "    \"\"\"Calculates the Mean Squared Error between `actuals` and `predicteds`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actuals: np.array\n",
    "        A numpy array of the actual values.\n",
    "    predicteds: np.array\n",
    "        A numpy array of the predicted values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        A float representing the Mean Squared Error between `actuals` and\n",
    "        `predicteds`.\n",
    "    \n",
    "    \"\"\"\n",
    "    return (((actuals - predicteds)**2).sum()) / (len(actuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate targets and data.\n",
    "\n",
    "Then split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "targets = data_df['overall']\n",
    "feature_data = data_df.drop(columns=['overall'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    feature_data, targets, shuffle=True, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting\n",
    "\n",
    "Throughout the model fitting process we will keep 3 arrays that store the model name, training error, and validation error respectively for all models that we prototype.\n",
    "\n",
    "##### Baselines\n",
    "\n",
    "We will look at two simple baseline models.\n",
    "\n",
    "The first is the same baseline model implemented in `baseline.py`. But we will evaluate its performance on the validation set in order to fit models and compare performance on data that is distinct from the test set.\n",
    "\n",
    "In this model we simply compute the average rating and assign this as our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "train_errors = []\n",
    "validation_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_on_average(targets, avg):\n",
    "    \"\"\"Computers the error based on using average rating as the prediction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    targets: np.array\n",
    "        The actual ratings.\n",
    "    avg: float\n",
    "        The predicted rating based on an average.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        A float representing the mean squared error from predicting\n",
    "        based on `avg`.\n",
    "    \n",
    "    \"\"\"\n",
    "    return calculate_MSE(targets, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error based on average prediction: 0.986\n",
      "Validation error based on average prediction: 1.000\n"
     ]
    }
   ],
   "source": [
    "train_avg = y_train.mean()\n",
    "\n",
    "model_names.append(\"Average\")\n",
    "train_errors.append(error_on_average(y_train, train_avg))\n",
    "validation_errors.append(error_on_average(y_val, train_avg))\n",
    "\n",
    "print(\"Training error based on average prediction: %.3f\" % train_errors[0])\n",
    "print(\"Validation error based on average prediction: %.3f\" % validation_errors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second baseline model is slightly more complicated. We will calculate three types of quantities:\n",
    "*  The overall average\n",
    "*  The difference between the average rating for each item and the overall average\n",
    "*  The difference between the average rating for each user and the overall average\n",
    "\n",
    "Our prediction for a particular user and item will then be the sum of these 3 quantities.\n",
    "\n",
    "We will denote this model as Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "train_avg_total = y_train.mean()\n",
    "train_user_avg = train_df.groupby(train_df['reviewerID'], as_index=False)['overall'].mean()\n",
    "train_item_avg = train_df.groupby(train_df['itemID'], as_index=False)['overall'].mean()\n",
    "train_user_avg.columns = ['reviewerID', 'userAverage']\n",
    "train_item_avg.columns = ['itemID', 'itemAverage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_rating(rating):\n",
    "    \"\"\"Thresholds `rating` to lie in the range [1, 5].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rating: float\n",
    "        The rating to be thresholded.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        A float representing the thresholded rating.\n",
    "    \n",
    "    \"\"\"\n",
    "    if rating < 1:\n",
    "        return 1\n",
    "    if rating > 5:\n",
    "        return 5\n",
    "    return rating\n",
    "\n",
    "def weighted_average_error(X, y, total_avg, user_avgs, item_avgs):\n",
    "    \"\"\"Calculates the error based on the weighted average prediction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pd.DataFrame\n",
    "        The DataFrame of features.\n",
    "    y: np.array\n",
    "        A numpy array containing the targets\n",
    "    total_avg: float\n",
    "        The average across all users/items.\n",
    "    user_avgs: pd.DataFrame\n",
    "        A DataFrame containing the average rating for each user.\n",
    "    item_avgs: pd.DataFrame\n",
    "        A DataFrame containing the average rating for each item.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        A float representing the mean squared error of the predictions.\n",
    "    \n",
    "    \"\"\"\n",
    "    df_user = pd.merge(X, user_avgs, how='left', on=['reviewerID'])\n",
    "    df_final = pd.merge(df_user, item_avgs, how='left', on=['itemID'])\n",
    "    df_final = df_final[['userAverage', 'itemAverage']]\n",
    "    df_final.fillna(total_avg)\n",
    "    print(len(df_final) == len(y))\n",
    "    df_final['pred'] = df_final['userAverage'] + df_final['itemAverage'] - total_avg\n",
    "    df_final['pred'].apply(lambda x: threshold_rating(x))\n",
    "    return calculate_MSE(y, df_final['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "Training error based on weighted average prediction: 1.613\n",
      "Validation error based on weighted average prediction: 0.293\n"
     ]
    }
   ],
   "source": [
    "train_MSE = weighted_average_error(X_train, y_train, train_avg_total, train_user_avg, train_item_avg)\n",
    "val_MSE = weighted_average_error(X_val, y_val, train_avg_total, train_user_avg, train_item_avg)\n",
    "\n",
    "print(\"Training error based on weighted average prediction: %.3f\" % train_MSE)\n",
    "print(\"Validation error based on weighted average prediction: %.3f\" % val_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc2515-env-3.8",
   "language": "python",
   "name": "csc2515-env-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
